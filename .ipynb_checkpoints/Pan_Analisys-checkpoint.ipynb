{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization and Cleaning\n",
    "1 -  First step is to import the data using pandas and visualize it's contentes\n",
    "\n",
    "2 - After that we need to solved what to do with the NaNs for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('problem1_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>ALTURA</th>\n",
       "      <th>CAPACIDADE_(L)</th>\n",
       "      <th>COMPOSICAO</th>\n",
       "      <th>COR</th>\n",
       "      <th>FORMATO</th>\n",
       "      <th>LARGURA</th>\n",
       "      <th>MARCA</th>\n",
       "      <th>PARA_LAVA_LOUCAS</th>\n",
       "      <th>PARA_MICRO_ONDAS</th>\n",
       "      <th>PESO</th>\n",
       "      <th>PROFUNDIDADE</th>\n",
       "      <th>TEMPO_GARANTIA</th>\n",
       "      <th>TEM_FERRO_FUNDIDO</th>\n",
       "      <th>TEM_GRELHA</th>\n",
       "      <th>TEM_TAMPA</th>\n",
       "      <th>TIPO_PRODUTO</th>\n",
       "      <th>TIPO_WOK</th>\n",
       "      <th>ITEM_PRICE</th>\n",
       "      <th>INTERESTED</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SESSION_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86.709770</th>\n",
       "      <td>264220456</td>\n",
       "      <td>30.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALUMINIO</td>\n",
       "      <td>VINHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>LA CUISINE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NAO</td>\n",
       "      <td>SIM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PANELA</td>\n",
       "      <td>NAO</td>\n",
       "      <td>199.990000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73.156401</th>\n",
       "      <td>238630912</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALUMINIO</td>\n",
       "      <td>COLORIDO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>TRAMONTINA</td>\n",
       "      <td>No</td>\n",
       "      <td>no</td>\n",
       "      <td>150.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PIPOQUEIRA</td>\n",
       "      <td>NAO</td>\n",
       "      <td>105.112581</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952.331024</th>\n",
       "      <td>218228122</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INOX</td>\n",
       "      <td>INOX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>LA CUISINE</td>\n",
       "      <td>Yes</td>\n",
       "      <td>no</td>\n",
       "      <td>190.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ESPAGUETEIRA</td>\n",
       "      <td>NAO</td>\n",
       "      <td>139.990000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637.759106</th>\n",
       "      <td>253661510</td>\n",
       "      <td>49.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ALUMINIO</td>\n",
       "      <td>VERMELHO</td>\n",
       "      <td>REDONDO</td>\n",
       "      <td>41.5</td>\n",
       "      <td>TRAMONTINA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PIPOQUEIRA</td>\n",
       "      <td>NAO</td>\n",
       "      <td>103.293333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478.531428</th>\n",
       "      <td>253661510</td>\n",
       "      <td>49.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ALUMINIO</td>\n",
       "      <td>VERMELHO</td>\n",
       "      <td>REDONDO</td>\n",
       "      <td>41.5</td>\n",
       "      <td>TRAMONTINA</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NAO</td>\n",
       "      <td>NAO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PIPOQUEIRA</td>\n",
       "      <td>NAO</td>\n",
       "      <td>103.330242</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ITEM_ID  ALTURA  CAPACIDADE_(L) COMPOSICAO       COR  FORMATO  \\\n",
       "SESSION_ID                                                                    \n",
       "86.709770   264220456    30.5             NaN   ALUMINIO     VINHO      NaN   \n",
       "73.156401   238630912    22.0             NaN   ALUMINIO  COLORIDO      NaN   \n",
       "952.331024  218228122    24.0             NaN       INOX      INOX      NaN   \n",
       "637.759106  253661510    49.5             6.0   ALUMINIO  VERMELHO  REDONDO   \n",
       "478.531428  253661510    49.5             6.0   ALUMINIO  VERMELHO  REDONDO   \n",
       "\n",
       "            LARGURA       MARCA PARA_LAVA_LOUCAS PARA_MICRO_ONDAS   PESO  \\\n",
       "SESSION_ID                                                                 \n",
       "86.709770      14.0  LA CUISINE              NaN              NaN    NaN   \n",
       "73.156401      24.0  TRAMONTINA               No               no  150.0   \n",
       "952.331024     20.0  LA CUISINE              Yes               no  190.0   \n",
       "637.759106     41.5  TRAMONTINA              Yes              NaN  120.0   \n",
       "478.531428     41.5  TRAMONTINA              Yes              NaN  120.0   \n",
       "\n",
       "            PROFUNDIDADE  TEMPO_GARANTIA TEM_FERRO_FUNDIDO TEM_GRELHA  \\\n",
       "SESSION_ID                                                              \n",
       "86.709770           50.0             3.0               NAO        SIM   \n",
       "73.156401           40.0            12.0               NAO        NAO   \n",
       "952.331024          20.0             3.0               NAO        NAO   \n",
       "637.759106          47.0             NaN               NAO        NAO   \n",
       "478.531428          47.0             NaN               NAO        NAO   \n",
       "\n",
       "            TEM_TAMPA  TIPO_PRODUTO TIPO_WOK  ITEM_PRICE  INTERESTED  \n",
       "SESSION_ID                                                            \n",
       "86.709770         1.0        PANELA      NAO  199.990000         0.0  \n",
       "73.156401         1.0    PIPOQUEIRA      NAO  105.112581         0.0  \n",
       "952.331024        1.0  ESPAGUETEIRA      NAO  139.990000         0.0  \n",
       "637.759106        1.0    PIPOQUEIRA      NAO  103.293333         1.0  \n",
       "478.531428        1.0    PIPOQUEIRA      NAO  103.330242         0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index('SESSION_ID',inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 180275 entries, 86.7097703783 to 222.930790647\n",
      "Data columns (total 20 columns):\n",
      "ITEM_ID              180275 non-null int64\n",
      "ALTURA               171007 non-null float64\n",
      "CAPACIDADE_(L)       76671 non-null float64\n",
      "COMPOSICAO           156978 non-null object\n",
      "COR                  170251 non-null object\n",
      "FORMATO              90011 non-null object\n",
      "LARGURA              171007 non-null float64\n",
      "MARCA                180001 non-null object\n",
      "PARA_LAVA_LOUCAS     104086 non-null object\n",
      "PARA_MICRO_ONDAS     86402 non-null object\n",
      "PESO                 98524 non-null float64\n",
      "PROFUNDIDADE         171007 non-null float64\n",
      "TEMPO_GARANTIA       122770 non-null float64\n",
      "TEM_FERRO_FUNDIDO    180275 non-null object\n",
      "TEM_GRELHA           180275 non-null object\n",
      "TEM_TAMPA            180275 non-null float64\n",
      "TIPO_PRODUTO         180275 non-null object\n",
      "TIPO_WOK             180275 non-null object\n",
      "ITEM_PRICE           167178 non-null float64\n",
      "INTERESTED           180275 non-null float64\n",
      "dtypes: float64(9), int64(1), object(10)\n",
      "memory usage: 28.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 27564 entries, 14.583125013599998 to 346.530445031\n",
      "Data columns (total 20 columns):\n",
      "ITEM_ID              27564 non-null int64\n",
      "ALTURA               27564 non-null float64\n",
      "CAPACIDADE_(L)       27564 non-null float64\n",
      "COMPOSICAO           27564 non-null object\n",
      "COR                  27564 non-null object\n",
      "FORMATO              27564 non-null object\n",
      "LARGURA              27564 non-null float64\n",
      "MARCA                27564 non-null object\n",
      "PARA_LAVA_LOUCAS     27564 non-null object\n",
      "PARA_MICRO_ONDAS     27564 non-null object\n",
      "PESO                 27564 non-null float64\n",
      "PROFUNDIDADE         27564 non-null float64\n",
      "TEMPO_GARANTIA       27564 non-null float64\n",
      "TEM_FERRO_FUNDIDO    27564 non-null object\n",
      "TEM_GRELHA           27564 non-null object\n",
      "TEM_TAMPA            27564 non-null float64\n",
      "TIPO_PRODUTO         27564 non-null object\n",
      "TIPO_WOK             27564 non-null object\n",
      "ITEM_PRICE           27564 non-null float64\n",
      "INTERESTED           27564 non-null float64\n",
      "dtypes: float64(9), int64(1), object(10)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "cleared_df = df.dropna()\n",
    "cleared_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27564\n"
     ]
    }
   ],
   "source": [
    "cleared_df.shape[0]/df.shape[0]*100\n",
    "print(cleared_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the NANs\n",
    "If we simply cleared all the NaN we would lose 85% of the information so we need to see how to solve the NAN issue for each column. The information we have is the ITEM_ID, we will try to get the information for each type of item and fill it in the missing value. I'm assuming that the ITEM_ID is the product type so for the same product type the characteristics would be the same. This logic would not be used for price because this can change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "item_IDS =  df.ITEM_ID.unique()\n",
    "print(len(item_IDS))\n",
    "total_updated = 0\n",
    "for id in item_IDS:\n",
    "    filtered = df.loc[df['ITEM_ID'] == id].head().dropna()\n",
    "    if(filtered.size!=0):\n",
    "       total_updated +=1\n",
    "    \n",
    "    \n",
    "print(total_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the Data above we can see that only 31 products have all the information so we need to find another strategy to fill in the NaN. Also we can see if we would drop the NAN rows we would have information only about 31 products\n",
    "\n",
    "The First step will be for each column that has a NaN value we will create another categoric column, that will indicate for us if the product has or not the information related with the column. This will help the algoritm to understand if the information is relevant on the classification. After that the NAN will be replaced by zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALTURA', 'CAPACIDADE_(L)', 'COMPOSICAO', 'COR', 'FORMATO', 'LARGURA', 'MARCA', 'PARA_LAVA_LOUCAS', 'PARA_MICRO_ONDAS', 'PESO', 'PROFUNDIDADE', 'TEMPO_GARANTIA', 'ITEM_PRICE']\n",
      "['ITEM_ID', 'TEM_FERRO_FUNDIDO', 'TEM_GRELHA', 'TEM_TAMPA', 'TIPO_PRODUTO', 'TIPO_WOK', 'INTERESTED']\n"
     ]
    }
   ],
   "source": [
    "columns_with_missing_info = []\n",
    "columns_with_all_info = []\n",
    "for column in df.columns:\n",
    "    if(df[column].isna().sum()>0):\n",
    "        columns_with_missing_info.append(column)\n",
    "        new_column = column+\"_CONTAINS_INFO\"\n",
    "        df[new_column] = df[column].isna()\n",
    "    else:\n",
    "        if (column.find(\"_CONTAINS_INFO\")==-1):\n",
    "            columns_with_all_info.append(column)\n",
    "\n",
    "print(columns_with_missing_info)\n",
    "print(columns_with_all_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 6 numerical features missing information \n",
    "- ALTURA, CAPACIDADE_(L),LARGURA,PESO,PROFUNDIDADE,TEMPO_GARANTIA,ITEM_PRICE\n",
    "\n",
    "We have 5 categorical features missing information \n",
    "- COMPOSICAO, COR, FORMATO, MARCA, PARA_LAVA_LOUCAS, PARA_MICRO_ONDAS\n",
    "\n",
    "We are ignoring SESSION_ID for now because that information will be used later. For the missing information on the numerical columns we will use a LINEAR REGRESSION to infer de value for NAN. So in the following steps we will create the linear regression for each missing of those. The same process will be used on he Categorical Data. However to use the build in interpolation feature we have to put all the lines containing all the information at the begining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols= ['COMPOSICAO','COR','FORMATO','MARCA','PARA_LAVA_LOUCAS','PARA_MICRO_ONDAS','TEM_FERRO_FUNDIDO','TEM_GRELHA','TEM_TAMPA','TIPO_PRODUTO','TIPO_WOK']\n",
    "for col in categorical_cols: \n",
    "    df.sort_values(by=col,axis=0,ascending=False,inplace=True)\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[col]= (df[col].cat.codes.replace(-1, np.nan).interpolate().astype(int).astype('category').cat.rename_categories(df[col].cat.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['ALTURA', 'CAPACIDADE_(L)','LARGURA','PESO','PROFUNDIDADE','TEMPO_GARANTIA','ITEM_PRICE']\n",
    "for col in numerical_cols: \n",
    "    df.sort_values(by=col,axis=0,ascending=False,inplace=True)\n",
    "    df[col]= df[col].interpolate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the System\n",
    "Now that we have the dataset clean and without NaN we can start to try to use ML algorithms to predict the data. First we need to encode the categorical columns using one_hot encoding to avoid missing interpretation of the data based on the int values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_reg = pd.get_dummies(df, columns=categorical_cols).copy(deep=True)\n",
    "df_for_reg = df_for_reg.drop(columns=['ITEM_ID'])\n",
    "df_for_reg = df_for_reg.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split  \n",
    "regressors = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the data set in a simple MultiLayerPerceptron to see the acuracy without any fine tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.35048718\n",
      "Iteration 2, loss = 0.32308092\n",
      "Iteration 3, loss = 0.34470836\n",
      "Iteration 4, loss = 0.33191449\n",
      "Iteration 5, loss = 0.33015378\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "INTERESTED Accuracy: 0.9135325833721627\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_for_reg.sort_index()\n",
    "\n",
    "classifier = MLPClassifier(verbose=True)  \n",
    "y = df_for_reg['INTERESTED'].values\n",
    "x = df_for_reg.loc[:, df_for_reg.columns != 'INTERESTED'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "classifier.fit(X_train, y_train)  \n",
    "result =classifier.score(X_test,y_test)\n",
    "print(column+\" Accuracy: \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without any fine tunning we have a accuracy of 91%. Let See the Parameters of the current MLP to see how it's set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will try to change de number of nodes in the hidden layer to see if there is any improvment. Based on the results we will check the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9146419933879163\n",
      "Iteration: 0 HiddenLayers: {84}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-0d56a0c3ccde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_for_reg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'INTERESTED'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_for_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_for_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'INTERESTED'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 1675\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1673\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m     return list(chain.from_iterable((safe_indexing(a, train),\n\u001b[0;32m-> 1675\u001b[0;31m                                      safe_indexing(a, test)) for a in arrays))\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36msafe_indexing\u001b[0;34m(X, indices)\u001b[0m\n\u001b[1;32m    108\u001b[0m                                    indices.dtype.kind == 'i'):\n\u001b[1;32m    109\u001b[0m             \u001b[0;31m# This is often substantially faster than X[indices]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features= len(df_for_reg.columns)\n",
    "bestHidden = ()\n",
    "bestAc = 0;\n",
    "for i in range(1,3):\n",
    "    for j in range(5):        \n",
    "        hidden_layers = set(np.random.randint(features*0.20,high=features*0.80,size=(1,i))[0])       \n",
    "        classifier = MLPClassifier(hidden_layer_sizes=hidden_layers)\n",
    "        y = df_for_reg['INTERESTED'].values\n",
    "        x = df_for_reg.loc[:, df_for_reg.columns != 'INTERESTED'].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "        classifier.fit(X_train, y_train)  \n",
    "        result =classifier.score(X_test,y_test)\n",
    "        if(bestAc<result):\n",
    "            bestAc = result\n",
    "            bestHidden = hidden_layers        \n",
    "            print(\"Accuracy: \" + str(result))\n",
    "            print(\"Iteration: \"+ str(j) +\" HiddenLayers: \" + str(hidden_layers))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no great improvment on the accuracy on this path so we will keep on 2 layers (features, features/2). Now we will try to improve the parameters of the MLP. We will keep the ReLu because itÅ› the most modern activation function. But we will change the rest to achieve a better performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38841898\n",
      "Iteration 2, loss = 0.38532696\n",
      "Iteration 3, loss = 0.34168866\n",
      "Iteration 4, loss = 0.32654298\n",
      "Iteration 5, loss = 0.32013656\n",
      "Iteration 6, loss = 0.31682868\n",
      "Iteration 7, loss = 0.31501522\n",
      "Iteration 8, loss = 0.31373360\n",
      "Iteration 9, loss = 0.31276521\n",
      "Iteration 10, loss = 0.31202331\n",
      "Accuracy: 0.9132441367680667\n"
     ]
    }
   ],
   "source": [
    "features= len(df_for_reg.columns)\n",
    "hidden_layers = (features, int(features*0.75))\n",
    "classifier_invscaling = MLPClassifier(verbose=True, hidden_layer_sizes=hidden_layers,learning_rate='invscaling',solver='sgd')\n",
    "y = df_for_reg['INTERESTED'].values\n",
    "x = df_for_reg.loc[:, df_for_reg.columns != 'INTERESTED'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "classifier_invscaling.fit(X_train, y_train)  \n",
    "result =classifier_invscaling.score(X_test,y_test)\n",
    "print(\"Accuracy: \" + str(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.38219318\n",
      "Iteration 2, loss = 0.30630808\n",
      "Iteration 3, loss = 0.30248198\n",
      "Iteration 4, loss = 0.30026451\n",
      "Iteration 5, loss = 0.30034231\n",
      "Iteration 6, loss = 0.29663178\n",
      "Iteration 7, loss = 0.29570704\n",
      "Iteration 8, loss = 0.29539211\n",
      "Iteration 9, loss = 0.29530498\n",
      "Iteration 10, loss = 0.29373458\n",
      "Iteration 11, loss = 0.29292255\n",
      "Iteration 12, loss = 0.29253369\n",
      "Iteration 13, loss = 0.29295028\n",
      "Iteration 14, loss = 0.29174020\n",
      "Iteration 15, loss = 0.29100245\n",
      "Iteration 16, loss = 0.29046989\n",
      "Iteration 17, loss = 0.29048739\n",
      "Iteration 18, loss = 0.29011551\n",
      "Iteration 19, loss = 0.28913195\n",
      "Iteration 20, loss = 0.28912507\n",
      "Iteration 21, loss = 0.28939464\n",
      "Iteration 22, loss = 0.28841806\n",
      "Iteration 23, loss = 0.28834277\n",
      "Iteration 24, loss = 0.29732936\n",
      "Iteration 25, loss = 0.29639548\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000200\n",
      "Iteration 26, loss = 0.29230980\n",
      "Iteration 27, loss = 0.28956829\n",
      "Iteration 28, loss = 0.28870447\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000040\n",
      "Iteration 29, loss = 0.28777383\n",
      "Iteration 30, loss = 0.28754156\n",
      "Iteration 31, loss = 0.28721653\n",
      "Iteration 32, loss = 0.28703783\n",
      "Iteration 33, loss = 0.28691969\n",
      "Iteration 34, loss = 0.28683885\n",
      "Iteration 35, loss = 0.28666603\n",
      "Iteration 36, loss = 0.28687449\n",
      "Iteration 37, loss = 0.28683695\n",
      "Iteration 38, loss = 0.28676756\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000008\n",
      "Iteration 39, loss = 0.28640518\n",
      "Iteration 40, loss = 0.28632658\n",
      "Iteration 41, loss = 0.28631654\n",
      "Iteration 42, loss = 0.28634837\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000002\n",
      "Iteration 43, loss = 0.28625183\n",
      "Iteration 44, loss = 0.28623375\n",
      "Iteration 45, loss = 0.28622848\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 46, loss = 0.28621294\n",
      "Iteration 47, loss = 0.28621108\n",
      "Iteration 48, loss = 0.28620897\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "Accuracy: 0.9132885131686969\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = (features, int(features/2))\n",
    "classifier_adaptive = MLPClassifier(verbose=True, hidden_layer_sizes=hidden_layers,learning_rate='adaptive',solver='sgd')\n",
    "y = df_for_reg['INTERESTED'].values\n",
    "x = df_for_reg.loc[:, df_for_reg.columns != 'INTERESTED'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "classifier_adaptive.fit(X_train, y_train)  \n",
    "result =classifier_adaptive.score(X_test,y_test)\n",
    "print(\"Accuracy: \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accurary was never over 91% so we need to go bacck and try to engeneer the features to see if we can improve on this algorithm. If that doesn't change we will try other algorithms. The first thing is transform the numerical features in buckets for categorization and after that try to apply the algorithms again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALTURA</th>\n",
       "      <th>CAPACIDADE_(L)</th>\n",
       "      <th>LARGURA</th>\n",
       "      <th>PESO</th>\n",
       "      <th>PROFUNDIDADE</th>\n",
       "      <th>TEMPO_GARANTIA</th>\n",
       "      <th>ITEM_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180275.000000</td>\n",
       "      <td>180275.000000</td>\n",
       "      <td>180275.000000</td>\n",
       "      <td>180275.000000</td>\n",
       "      <td>180275.000000</td>\n",
       "      <td>180275.000000</td>\n",
       "      <td>180275.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.106552</td>\n",
       "      <td>1.826867</td>\n",
       "      <td>26.680072</td>\n",
       "      <td>170.390221</td>\n",
       "      <td>33.136967</td>\n",
       "      <td>9.765170</td>\n",
       "      <td>118.584038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.785682</td>\n",
       "      <td>2.349141</td>\n",
       "      <td>11.451800</td>\n",
       "      <td>1286.478914</td>\n",
       "      <td>16.415044</td>\n",
       "      <td>36.510763</td>\n",
       "      <td>136.281879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.619000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>36.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>100.339412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.700000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>32.700000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>139.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>44400.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2274.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ALTURA  CAPACIDADE_(L)        LARGURA           PESO  \\\n",
       "count  180275.000000   180275.000000  180275.000000  180275.000000   \n",
       "mean       29.106552        1.826867      26.680072     170.390221   \n",
       "std        15.785682        2.349141      11.451800    1286.478914   \n",
       "min         2.000000        0.045000       4.500000       0.619000   \n",
       "25%        16.000000        0.045000      18.500000       0.619000   \n",
       "50%        28.000000        0.045000      26.000000      60.000000   \n",
       "75%        42.700000        4.500000      32.700000     160.000000   \n",
       "max        84.000000       11.000000      91.000000   44400.000000   \n",
       "\n",
       "        PROFUNDIDADE  TEMPO_GARANTIA     ITEM_PRICE  \n",
       "count  180275.000000   180275.000000  180275.000000  \n",
       "mean       33.136967        9.765170     118.584038  \n",
       "std        16.415044       36.510763     136.281879  \n",
       "min         2.500000        1.000000       0.550000  \n",
       "25%        18.500000        1.000000      60.900000  \n",
       "50%        36.500000        3.000000     100.339412  \n",
       "75%        47.000000       12.000000     139.900000  \n",
       "max       148.000000      300.000000    2274.990000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ALTURA_BIN'] = pd.cut(df['ALTURA'], [0,2,16,28,43,84],labels=[1,2,3,4,5])\n",
    "df['CAPACIDADE_BIN'] = pd.cut(df['CAPACIDADE_(L)'], [0,0.045,4.5,11],labels=[1,2,3])\n",
    "df['LARGURA_BIN'] = pd.cut(df['LARGURA'], [0,4.5,18.5,26,33,91],labels=[1,2,3,4,5])\n",
    "df['PESO_BIN'] = pd.cut(df['PESO'], [0,0.62,60,160,44400],labels=[1,2,3,4])\n",
    "df['PROFUNDIDADE_BIN'] = pd.cut(df['PROFUNDIDADE'], [0,2.5,18.5,36.5,47,148],labels=[1,2,3,4,5])\n",
    "df['TEMPO_GARANTIA_BIN'] = pd.cut(df['TEMPO_GARANTIA'], [0,1,3,12,300],labels=[1,2,3,4])\n",
    "df['ITEM_PRICE_BIN'] = pd.cut(df['ITEM_PRICE'], [0,0.55,61,100,139,2275],labels=[1,2,3,4,5])\n",
    "df_for_reg2 = df.copy(deep=True)\n",
    "df_for_reg2 = df_for_reg2.drop(columns = numerical_cols)\n",
    "df_for_reg2 = pd.get_dummies(df_for_reg2, columns=categorical_cols)\n",
    "df_for_reg2 = pd.get_dummies(df_for_reg2, columns=['ALTURA_BIN','CAPACIDADE_BIN','PESO_BIN','PROFUNDIDADE_BIN','TEMPO_GARANTIA_BIN','ITEM_PRICE_BIN'])\n",
    "df_for_reg2 = df_for_reg2.drop(columns=['ITEM_ID'])\n",
    "df_for_reg2 = df_for_reg2.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 HiddenLayers: {124}\n",
      "Accuracy: 0.9138654063768887\n",
      "Iteration: 3 HiddenLayers: {54}\n",
      "Accuracy: 0.9159289090061905\n"
     ]
    }
   ],
   "source": [
    "features = df_for_reg2.shape[1]\n",
    "bestHidden = ()\n",
    "bestAc = 0\n",
    "for i in range(1,3):\n",
    "    for j in range(5):  \n",
    "        hidden_layers = set(np.random.randint(features*0.20,high=features*0.80,size=(1,i))[0])\n",
    "        \n",
    "        classifier = MLPClassifier(hidden_layer_sizes=hidden_layers)\n",
    "        y = df_for_reg['INTERESTED'].values.astype(float)\n",
    "        x = df_for_reg.loc[:, df_for_reg.columns != 'INTERESTED'].values.astype(float)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "        classifier.fit(X_train, y_train)  \n",
    "        result =classifier.score(X_test,y_test)\n",
    "        if(bestAc<result):\n",
    "            bestAc = result\n",
    "            bestHidden = hidden_layers        \n",
    "            print(\"Iteration: \"+ str(j) +\" HiddenLayers: \" + str(hidden_layers))\n",
    "            print(\"Accuracy: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(161, 80), learning_rate='adaptive',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_adaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.28536227\n",
      "Iteration 2, loss = 0.27948827\n",
      "Iteration 3, loss = 0.27795917\n",
      "Iteration 4, loss = 0.27746322\n",
      "Iteration 5, loss = 0.27679051\n",
      "Iteration 6, loss = 0.27651032\n",
      "Iteration 7, loss = 0.27611235\n",
      "Iteration 8, loss = 0.27605947\n",
      "Iteration 9, loss = 0.27579331\n",
      "Iteration 10, loss = 0.27550556\n",
      "Iteration 11, loss = 0.27535420\n",
      "Iteration 12, loss = 0.27547403\n",
      "Iteration 13, loss = 0.27532072\n",
      "Iteration 14, loss = 0.27508393\n",
      "Iteration 15, loss = 0.27496148\n",
      "Iteration 16, loss = 0.27473236\n",
      "Iteration 17, loss = 0.27476422\n",
      "Iteration 18, loss = 0.27452503\n",
      "Iteration 19, loss = 0.27462458\n",
      "Iteration 20, loss = 0.27449506\n",
      "Iteration 21, loss = 0.27452484\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 22, loss = 0.27362932\n",
      "Iteration 23, loss = 0.27339368\n",
      "Iteration 24, loss = 0.27336190\n",
      "Iteration 25, loss = 0.27328342\n",
      "Iteration 26, loss = 0.27328979\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 27, loss = 0.27301666\n",
      "Iteration 28, loss = 0.27296608\n",
      "Iteration 29, loss = 0.27296159\n",
      "Iteration 30, loss = 0.27296115\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 31, loss = 0.27288078\n",
      "Iteration 32, loss = 0.27287453\n",
      "Iteration 33, loss = 0.27287350\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 34, loss = 0.27285556\n",
      "Iteration 35, loss = 0.27285512\n",
      "Iteration 36, loss = 0.27285481\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 37, loss = 0.27285099\n",
      "Iteration 38, loss = 0.27285088\n",
      "Iteration 39, loss = 0.27285075\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 40, loss = 0.27285007\n",
      "Iteration 41, loss = 0.27285006\n",
      "Iteration 42, loss = 0.27285003\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 43, loss = 0.27284989\n",
      "Iteration 44, loss = 0.27284989\n",
      "Iteration 45, loss = 0.27284988\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 46, loss = 0.27284985\n",
      "Iteration 47, loss = 0.27284985\n",
      "Iteration 48, loss = 0.27284985\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "Accuracy: 0.913931970977834\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = set([features,int(features*0.5)])\n",
    "y = df_for_reg2['INTERESTED'].values.astype(float)\n",
    "x = df_for_reg2.loc[:, df_for_reg2.columns != 'INTERESTED'].values.astype(float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "classifier_adaptive = MLPClassifier(verbose=True, hidden_layer_sizes=hidden_layers,learning_rate_init=0.1,learning_rate='adaptive',solver='sgd')\n",
    "classifier_adaptive.fit(X_train, y_train)  \n",
    "result =classifier_adaptive.score(X_test,y_test)\n",
    "print(\"Accuracy: \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still didn't have any significant improvment. Let's try another Machine Learning Algorithm. Let's try SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(verbose=True).fit(X_train, y_train)\n",
    "result =svm.score(X_test,y_test)\n",
    "print(\"Accuracy: \" + str(result))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant difference in accuracy. However we can also encode de output in two classes, that way each outuput neuron can especialize in detect if the product is or not interessting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_col= ['INTERESTED']\n",
    "df_for_reg3 = pd.get_dummies(df_for_reg2, columns=categorical_col).copy(deep=True)\n",
    "df_for_reg3 = df_for_reg3.apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57567180\n",
      "Iteration 2, loss = 0.56654053\n",
      "Iteration 3, loss = 0.56216501\n",
      "Iteration 4, loss = 0.56237939\n",
      "Iteration 5, loss = 0.55990309\n",
      "Iteration 6, loss = 0.55865787\n",
      "Iteration 7, loss = 0.55823679\n",
      "Iteration 8, loss = 0.55760085\n",
      "Iteration 9, loss = 0.55811074\n",
      "Iteration 10, loss = 0.55726305\n",
      "Iteration 11, loss = 0.55649527\n",
      "Iteration 12, loss = 0.55629189\n",
      "Iteration 13, loss = 0.55645992\n",
      "Iteration 14, loss = 0.55614275\n",
      "Iteration 15, loss = 0.55560172\n",
      "Iteration 16, loss = 0.55539739\n",
      "Iteration 17, loss = 0.55525817\n",
      "Iteration 18, loss = 0.55515597\n",
      "Iteration 19, loss = 0.55487618\n",
      "Iteration 20, loss = 0.55485593\n",
      "Iteration 21, loss = 0.55458602\n",
      "Iteration 22, loss = 0.55442223\n",
      "Iteration 23, loss = 0.55443952\n",
      "Iteration 24, loss = 0.55492155\n",
      "Iteration 25, loss = 0.55452025\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 26, loss = 0.55257664\n",
      "Iteration 27, loss = 0.55229787\n",
      "Iteration 28, loss = 0.55219996\n",
      "Iteration 29, loss = 0.55206998\n",
      "Iteration 30, loss = 0.55216938\n",
      "Iteration 31, loss = 0.55197407\n",
      "Iteration 32, loss = 0.55198366\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 33, loss = 0.55148138\n",
      "Iteration 34, loss = 0.55134974\n",
      "Iteration 35, loss = 0.55134682\n",
      "Iteration 36, loss = 0.55132735\n",
      "Iteration 37, loss = 0.55132254\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 38, loss = 0.55126341\n",
      "Iteration 39, loss = 0.55121401\n",
      "Iteration 40, loss = 0.55118877\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 41, loss = 0.55114666\n",
      "Iteration 42, loss = 0.55114385\n",
      "Iteration 43, loss = 0.55114136\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 44, loss = 0.55113293\n",
      "Iteration 45, loss = 0.55113249\n",
      "Iteration 46, loss = 0.55113198\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 47, loss = 0.55113034\n",
      "Iteration 48, loss = 0.55113026\n",
      "Iteration 49, loss = 0.55113018\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 50, loss = 0.55112985\n",
      "Iteration 51, loss = 0.55112983\n",
      "Iteration 52, loss = 0.55112981\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 53, loss = 0.55112975\n",
      "Iteration 54, loss = 0.55112974\n",
      "Iteration 55, loss = 0.55112974\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "Accuracy: 0.9179480352348621\n"
     ]
    }
   ],
   "source": [
    "resultcols =[k for k in df_for_reg3.columns if k.find(\"INTERESTED\")!=-1]\n",
    "y = df_for_reg3[resultcols].values\n",
    "x = df_for_reg3[df_for_reg3.columns.difference(resultcols)].values\n",
    "classifier = MLPClassifier(verbose=True, hidden_layer_sizes=(x.shape[1],int(x.shape[1]/2)),\n",
    "                           learning_rate_init = 0.1,\n",
    "                           learning_rate='adaptive',solver='sgd')  \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "classifier.fit(X_train, y_train)  \n",
    "result =classifier.score(X_test,y_test)\n",
    "print(\"Accuracy: \" + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was no improvement as well, so we will try to implementa more complex NN in tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135206, 160)\n",
      "(135206, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Training Accuracy: 10.4559%\n",
      "Epoch 0   - Validation Accuracy: 10.5993%\n",
      "Epoch 10  - Training Accuracy: 91.3746%\n",
      "Epoch 10  - Validation Accuracy: 91.4243%\n",
      "Epoch 20  - Training Accuracy: 91.3746%\n",
      "Epoch 20  - Validation Accuracy: 91.4243%\n",
      "Epoch 30  - Training Accuracy: 91.3746%\n",
      "Epoch 30  - Validation Accuracy: 91.4243%\n",
      "Epoch 40  - Training Accuracy: 91.3746%\n",
      "Epoch 40  - Validation Accuracy: 91.4243%\n",
      "Epoch 42 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7326f98c0976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# feeding training data/examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_batch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0;31m#print(\"{:.4%}\".format((i/len(X_train))), end='\\r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnd-tf-lab/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.0001\n",
    "training_epochs = 100\n",
    "batch_size = int(x.shape[0]/100)  # Decrease batch size if you don't have enough memory\n",
    "\n",
    "n_input = x.shape[1]\n",
    "n_classes = 2  \n",
    "n_hidden_layer = x.shape[1] # layer number of features\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'hidden_layer_1': tf.Variable(tf.random_normal([n_hidden_layer, int(n_hidden_layer/2)])),\n",
    "    'out': tf.Variable(tf.random_normal([int(n_hidden_layer/2), n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'hidden_layer_1': tf.Variable(tf.random_normal([int(n_hidden_layer/2)])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "# tf Graph input\n",
    "x_tf = tf.placeholder(\"float\", [None, n_input])\n",
    "y_tf = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_tf, weights['hidden_layer']),biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['hidden_layer_1']),biases['hidden_layer_1'])\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_tf))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_tf, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        for i in range(0,len(X_train),batch_size):\n",
    "\n",
    "            start=i\n",
    "            end=i+batch_size\n",
    "            x_batch=X_train[start:end]\n",
    "            y_batch=y_train[start:end]\n",
    "            \n",
    "            # feeding training data/examples\n",
    "            sess.run(optimizer, feed_dict={x_tf:x_batch , y_tf:y_batch,keep_prob:0.3})\n",
    "            #print(\"{:.4%}\".format((i/len(X_train))), end='\\r')\n",
    "        \n",
    "            # Print status for every 10 epochs\n",
    "        print('Epoch {:<3}'.format(epoch), end='\\r')\n",
    "        if(epoch%10==0):\n",
    "            valid_accuracy = sess.run(\n",
    "                    accuracy,\n",
    "                    feed_dict={x_tf: X_test, y_tf: y_test,keep_prob: 1})\n",
    "            train_accuracy = sess.run(\n",
    "                    accuracy,\n",
    "                    feed_dict={x_tf: X_train, y_tf: y_train,keep_prob: 1})\n",
    "            print('Epoch {:<3} - Training Accuracy: {:.4%}'.format(\n",
    "                    epoch,\n",
    "                    train_accuracy))\n",
    "            print('Epoch {:<3} - Validation Accuracy: {:.4%}'.format(\n",
    "                    epoch,\n",
    "                    valid_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there was no great improvment either we will try to remove the interpolation of the input data to avoid adding noise to the model. To do data we will use NaN as a different category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv('problem1_dataset.csv')\n",
    "df_3.set_index('SESSION_ID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 180275 entries, 86.7097703783 to 222.930790647\n",
      "Columns: 140 entries, ITEM_ID to TIPO_WOK_nan\n",
      "dtypes: float64(8), int64(1), uint8(131)\n",
      "memory usage: 36.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_3 = pd.get_dummies(df_3, columns=categorical_cols, dummy_na=True)\n",
    "df_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3['ALTURA_BIN'] = pd.cut(df_3['ALTURA'], [0,2,16,28,43,84],labels=[1,2,3,4,5])\n",
    "df_3['CAPACIDADE_BIN'] = pd.cut(df_3['CAPACIDADE_(L)'], [0,0.045,4.5,11],labels=[1,2,3])\n",
    "df_3['LARGURA_BIN'] = pd.cut(df_3['LARGURA'], [0,4.5,18.5,26,33,91],labels=[1,2,3,4,5])\n",
    "df_3['PESO_BIN'] = pd.cut(df_3['PESO'], [0,0.62,60,160,44400],labels=[1,2,3,4])\n",
    "df_3['PROFUNDIDADE_BIN'] = pd.cut(df_3['PROFUNDIDADE'], [0,2.5,18.5,36.5,47,148],labels=[1,2,3,4,5])\n",
    "df_3['TEMPO_GARANTIA_BIN'] = pd.cut(df_3['TEMPO_GARANTIA'], [0,1,3,12,300],labels=[1,2,3,4])\n",
    "df_3['ITEM_PRICE_BIN'] = pd.cut(df_3['ITEM_PRICE'], [0,0.55,61,100,139,2275],labels=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPOSICAO_ACO ESMALTADO</th>\n",
       "      <th>COMPOSICAO_ALUMINIO</th>\n",
       "      <th>COMPOSICAO_CERAMICA</th>\n",
       "      <th>COMPOSICAO_INOX</th>\n",
       "      <th>COMPOSICAO_PORCELANA</th>\n",
       "      <th>COMPOSICAO_nan</th>\n",
       "      <th>COR_ACACIA</th>\n",
       "      <th>COR_AMARELO</th>\n",
       "      <th>COR_AZUL</th>\n",
       "      <th>COR_BERINGELA</th>\n",
       "      <th>...</th>\n",
       "      <th>ITEM_PRICE_BIN_5.0</th>\n",
       "      <th>ITEM_PRICE_BIN_nan</th>\n",
       "      <th>LARGURA_BIN_1.0</th>\n",
       "      <th>LARGURA_BIN_2.0</th>\n",
       "      <th>LARGURA_BIN_3.0</th>\n",
       "      <th>LARGURA_BIN_4.0</th>\n",
       "      <th>LARGURA_BIN_5.0</th>\n",
       "      <th>LARGURA_BIN_nan</th>\n",
       "      <th>INTERESTED_0.0</th>\n",
       "      <th>INTERESTED_1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SESSION_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86.709770</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73.156401</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952.331024</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637.759106</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478.531428</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            COMPOSICAO_ACO ESMALTADO  COMPOSICAO_ALUMINIO  \\\n",
       "SESSION_ID                                                  \n",
       "86.709770                          0                    1   \n",
       "73.156401                          0                    1   \n",
       "952.331024                         0                    0   \n",
       "637.759106                         0                    1   \n",
       "478.531428                         0                    1   \n",
       "\n",
       "            COMPOSICAO_CERAMICA  COMPOSICAO_INOX  COMPOSICAO_PORCELANA  \\\n",
       "SESSION_ID                                                               \n",
       "86.709770                     0                0                     0   \n",
       "73.156401                     0                0                     0   \n",
       "952.331024                    0                1                     0   \n",
       "637.759106                    0                0                     0   \n",
       "478.531428                    0                0                     0   \n",
       "\n",
       "            COMPOSICAO_nan  COR_ACACIA  COR_AMARELO  COR_AZUL  COR_BERINGELA  \\\n",
       "SESSION_ID                                                                     \n",
       "86.709770                0           0            0         0              0   \n",
       "73.156401                0           0            0         0              0   \n",
       "952.331024               0           0            0         0              0   \n",
       "637.759106               0           0            0         0              0   \n",
       "478.531428               0           0            0         0              0   \n",
       "\n",
       "                 ...        ITEM_PRICE_BIN_5.0  ITEM_PRICE_BIN_nan  \\\n",
       "SESSION_ID       ...                                                 \n",
       "86.709770        ...                         1                   0   \n",
       "73.156401        ...                         0                   0   \n",
       "952.331024       ...                         1                   0   \n",
       "637.759106       ...                         0                   0   \n",
       "478.531428       ...                         0                   0   \n",
       "\n",
       "            LARGURA_BIN_1.0  LARGURA_BIN_2.0  LARGURA_BIN_3.0  \\\n",
       "SESSION_ID                                                      \n",
       "86.709770                 0                1                0   \n",
       "73.156401                 0                0                1   \n",
       "952.331024                0                0                1   \n",
       "637.759106                0                0                0   \n",
       "478.531428                0                0                0   \n",
       "\n",
       "            LARGURA_BIN_4.0  LARGURA_BIN_5.0  LARGURA_BIN_nan  INTERESTED_0.0  \\\n",
       "SESSION_ID                                                                      \n",
       "86.709770                 0                0                0               1   \n",
       "73.156401                 0                0                0               1   \n",
       "952.331024                0                0                0               1   \n",
       "637.759106                0                1                0               0   \n",
       "478.531428                0                1                0               1   \n",
       "\n",
       "            INTERESTED_1.0  \n",
       "SESSION_ID                  \n",
       "86.709770                0  \n",
       "73.156401                0  \n",
       "952.331024               0  \n",
       "637.759106               1  \n",
       "478.531428               0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3 = df_3.drop(columns = numerical_cols)\n",
    "df_3 = pd.get_dummies(df_3, dummy_na=True, columns=['ALTURA_BIN','CAPACIDADE_BIN','PESO_BIN','PROFUNDIDADE_BIN','TEMPO_GARANTIA_BIN','ITEM_PRICE_BIN','LARGURA_BIN'])\n",
    "df_3 = df_3.drop(columns=['ITEM_ID'])\n",
    "categorical_col= ['INTERESTED']\n",
    "df_3 = pd.get_dummies(df_3, columns=categorical_col)\n",
    "df_3 = df_3.apply(pd.to_numeric, errors='ignore')\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_3.columns[df_3.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57042319\n",
      "Iteration 2, loss = 0.55913544\n",
      "Iteration 3, loss = 0.55690735\n",
      "Iteration 4, loss = 0.55541257\n",
      "Iteration 5, loss = 0.55409508\n",
      "Iteration 6, loss = 0.55321928\n",
      "Iteration 7, loss = 0.55240694\n",
      "Iteration 8, loss = 0.55214663\n",
      "Iteration 9, loss = 0.55165832\n",
      "Iteration 10, loss = 0.55107379\n",
      "Iteration 11, loss = 0.55099005\n",
      "Iteration 12, loss = 0.55086085\n",
      "Iteration 13, loss = 0.55078864\n",
      "Iteration 14, loss = 0.55068587\n",
      "Iteration 15, loss = 0.55018045\n",
      "Iteration 16, loss = 0.55009963\n",
      "Iteration 17, loss = 0.55009576\n",
      "Iteration 18, loss = 0.54979354\n",
      "Iteration 19, loss = 0.54981057\n",
      "Iteration 20, loss = 0.54966157\n",
      "Iteration 21, loss = 0.54945175\n",
      "Iteration 22, loss = 0.54966473\n",
      "Iteration 23, loss = 0.54943330\n",
      "Iteration 24, loss = 0.54912184\n",
      "Iteration 25, loss = 0.54905692\n",
      "Iteration 26, loss = 0.54908656\n",
      "Iteration 27, loss = 0.54880059\n",
      "Iteration 28, loss = 0.54910053\n",
      "Iteration 29, loss = 0.54861955\n",
      "Iteration 30, loss = 0.54865312\n",
      "Iteration 31, loss = 0.54925045\n",
      "Iteration 32, loss = 0.54901445\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 33, loss = 0.54705376\n",
      "Iteration 34, loss = 0.54663035\n",
      "Iteration 35, loss = 0.54663074\n",
      "Iteration 36, loss = 0.54652230\n",
      "Iteration 37, loss = 0.54640414\n",
      "Iteration 38, loss = 0.54641610\n",
      "Iteration 39, loss = 0.54637016\n",
      "Iteration 40, loss = 0.54634044\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 41, loss = 0.54578232\n",
      "Iteration 42, loss = 0.54570875\n",
      "Iteration 43, loss = 0.54569419\n",
      "Iteration 44, loss = 0.54569133\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 45, loss = 0.54553572\n",
      "Iteration 46, loss = 0.54553312\n",
      "Iteration 47, loss = 0.54553086\n",
      "Iteration 48, loss = 0.54552654\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 49, loss = 0.54549560\n",
      "Iteration 50, loss = 0.54549560\n",
      "Iteration 51, loss = 0.54549468\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 52, loss = 0.54548800\n",
      "Iteration 53, loss = 0.54548791\n",
      "Iteration 54, loss = 0.54548786\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 55, loss = 0.54548645\n",
      "Iteration 56, loss = 0.54548642\n",
      "Iteration 57, loss = 0.54548641\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 58, loss = 0.54548614\n",
      "Iteration 59, loss = 0.54548614\n",
      "Iteration 60, loss = 0.54548613\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 61, loss = 0.54548608\n",
      "Iteration 62, loss = 0.54548608\n",
      "Iteration 63, loss = 0.54548607\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "Accuracy: 0.9153742039983137\n"
     ]
    }
   ],
   "source": [
    "resultcols =[k for k in df_3.columns if k.find(\"INTERESTED\")!=-1]\n",
    "y = df_3[resultcols].values\n",
    "x = df_3[df_3.columns.difference(resultcols)].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)  \n",
    "classifier = MLPClassifier(verbose=True, hidden_layer_sizes=(x.shape[1],int(x.shape[1]/2)),\n",
    "                           learning_rate_init = 0.1,\n",
    "                           learning_rate='adaptive',solver='sgd')  \n",
    "classifier.fit(X_train, y_train)  \n",
    "result =classifier.score(X_test,y_test)\n",
    "print(\"Accuracy: \" + str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   - Training Accuracy: 66.0518%\n",
      "Epoch 0   - Validation Accuracy: 66.3494%\n",
      "Epoch 5   - Training Accuracy: 66.1073%\n",
      "Epoch 5   - Validation Accuracy: 66.5801%\n",
      "Epoch 10  - Training Accuracy: 66.2537%\n",
      "Epoch 10  - Validation Accuracy: 66.7332%\n",
      "Epoch 15  - Training Accuracy: 66.4283%\n",
      "Epoch 15  - Validation Accuracy: 66.9019%\n",
      "Epoch 20  - Training Accuracy: 66.5326%\n",
      "Epoch 20  - Validation Accuracy: 67.0616%\n",
      "Epoch 25  - Training Accuracy: 69.7506%\n",
      "Epoch 25  - Validation Accuracy: 69.7486%\n",
      "Epoch 30  - Training Accuracy: 70.4340%\n",
      "Epoch 30  - Validation Accuracy: 70.6339%\n",
      "Epoch 35  - Training Accuracy: 70.6625%\n",
      "Epoch 35  - Validation Accuracy: 70.8514%\n",
      "Epoch 40  - Training Accuracy: 70.6522%\n",
      "Epoch 40  - Validation Accuracy: 70.9512%\n",
      "Epoch 45  - Training Accuracy: 70.7846%\n",
      "Epoch 45  - Validation Accuracy: 71.1065%\n",
      "Epoch 50  - Training Accuracy: 70.8667%\n",
      "Epoch 50  - Validation Accuracy: 71.2175%\n",
      "Epoch 55  - Training Accuracy: 70.8948%\n",
      "Epoch 55  - Validation Accuracy: 71.2574%\n",
      "Epoch 60  - Training Accuracy: 72.3592%\n",
      "Epoch 60  - Validation Accuracy: 72.6863%\n",
      "Epoch 65  - Training Accuracy: 72.8888%\n",
      "Epoch 65  - Validation Accuracy: 73.1944%\n",
      "Epoch 70  - Training Accuracy: 73.3754%\n",
      "Epoch 70  - Validation Accuracy: 73.5694%\n",
      "Epoch 75  - Training Accuracy: 73.5744%\n",
      "Epoch 75  - Validation Accuracy: 73.7669%\n",
      "Epoch 80  - Training Accuracy: 73.6632%\n",
      "Epoch 80  - Validation Accuracy: 73.8512%\n",
      "Epoch 85  - Training Accuracy: 73.8074%\n",
      "Epoch 85  - Validation Accuracy: 74.0221%\n",
      "Epoch 90  - Training Accuracy: 73.8140%\n",
      "Epoch 90  - Validation Accuracy: 74.0309%\n",
      "Epoch 95  - Training Accuracy: 73.9457%\n",
      "Epoch 95  - Validation Accuracy: 74.0842%\n",
      "Epoch 100 - Training Accuracy: 74.2792%\n",
      "Epoch 100 - Validation Accuracy: 74.4436%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "training_epochs = 100\n",
    "batch_size = int(x.shape[0])  \n",
    "learning_rate = 0.1\n",
    "\n",
    "n_input = x.shape[1]\n",
    "n_classes = 2  \n",
    "n_hidden_layer = x.shape[1] # layer number of features\n",
    "weights = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_input, n_hidden_layer])),\n",
    "    'hidden_layer_1': tf.Variable(tf.random_normal([n_hidden_layer, int(n_hidden_layer/2)])),\n",
    "    'out': tf.Variable(tf.random_normal([int(n_hidden_layer/2), n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden_layer': tf.Variable(tf.random_normal([n_hidden_layer])),\n",
    "    'hidden_layer_1': tf.Variable(tf.random_normal([int(n_hidden_layer/2)])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "# tf Graph input\n",
    "x_tf = tf.placeholder(\"float\", [None, n_input])\n",
    "y_tf = tf.placeholder(\"float\", [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # probability to keep units\n",
    "\n",
    "# Hidden layer with RELU activation\n",
    "layer_1 = tf.add(tf.matmul(x_tf, weights['hidden_layer']),biases['hidden_layer'])\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "layer_1 = tf.nn.dropout(layer_1, keep_prob)\n",
    "\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['hidden_layer_1']),biases['hidden_layer_1'])\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "layer_2 = tf.nn.dropout(layer_2, keep_prob)\n",
    "\n",
    "# Output layer with linear activation\n",
    "logits = tf.add(tf.matmul(layer_2, weights['out']), biases['out'])\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_tf))\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y_tf, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs+1):\n",
    "        for i in range(0,len(X_train),batch_size):\n",
    "            #random_batch = np.random.choice(X_train.shape[0], int(X_train.shape[0] / batch_size))\n",
    "            start=i\n",
    "            end=i+batch_size\n",
    "            x_batch=X_train[start:end]\n",
    "            y_batch=y_train[start:end]         \n",
    "            # feeding training data/examples\n",
    "            sess.run(optimizer, feed_dict={x_tf:x_batch , y_tf:y_batch,keep_prob:0.3})\n",
    "            #print(\"{:.4%}\".format((i/len(X_train))), end='\\r')\n",
    "        \n",
    "            # Print status for every 10 epochs\n",
    "        print('Epoch {:<3}'.format(epoch), end='\\r')\n",
    "        np.random.shuffle(X_train)\n",
    "        np.random.shuffle(y_train)\n",
    "       \n",
    "            \n",
    "        if(epoch%5==0):\n",
    "            valid_accuracy = sess.run(\n",
    "                    accuracy,\n",
    "                    feed_dict={x_tf: X_test, y_tf: y_test,keep_prob: 1})\n",
    "            train_accuracy = sess.run(\n",
    "                    accuracy,\n",
    "                    feed_dict={x_tf: X_train, y_tf: y_train,keep_prob: 1})\n",
    "            print('Epoch {:<3} - Training Accuracy: {:.4%}'.format(\n",
    "                    epoch,\n",
    "                    train_accuracy))\n",
    "            print('Epoch {:<3} - Validation Accuracy: {:.4%}'.format(\n",
    "                    epoch,\n",
    "                    valid_accuracy))\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analisys\n",
    "All the attempts made to improve the performance resulted in the same accuracy between 91% and 92%. So we need to take a look at the data  to see if any other insigths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Float64Index: 180275 entries, 86.7097703783 to 222.930790647\n",
      "Data columns (total 20 columns):\n",
      "ITEM_ID              180275 non-null int64\n",
      "ALTURA               171007 non-null float64\n",
      "CAPACIDADE_(L)       76671 non-null float64\n",
      "COMPOSICAO           156978 non-null object\n",
      "COR                  170251 non-null object\n",
      "FORMATO              90011 non-null object\n",
      "LARGURA              171007 non-null float64\n",
      "MARCA                180001 non-null object\n",
      "PARA_LAVA_LOUCAS     104086 non-null object\n",
      "PARA_MICRO_ONDAS     86402 non-null object\n",
      "PESO                 98524 non-null float64\n",
      "PROFUNDIDADE         171007 non-null float64\n",
      "TEMPO_GARANTIA       122770 non-null float64\n",
      "TEM_FERRO_FUNDIDO    180275 non-null object\n",
      "TEM_GRELHA           180275 non-null object\n",
      "TEM_TAMPA            180275 non-null float64\n",
      "TIPO_PRODUTO         180275 non-null object\n",
      "TIPO_WOK             180275 non-null object\n",
      "ITEM_PRICE           167178 non-null float64\n",
      "INTERESTED           180275 non-null float64\n",
      "dtypes: float64(9), int64(1), object(10)\n",
      "memory usage: 28.9+ MB\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('problem1_dataset.csv')\n",
    "df.set_index('SESSION_ID',inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febde6dd9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['INTERESTED'].value_counts().plot(kind='pie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febe31cfbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['COMPOSICAO'].value_counts().plot(kind='pie')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febe18764a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['FORMATO'].value_counts().plot(kind='pie')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7febe4dd2a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1,3,1)\n",
    "df['ALTURA'].plot(kind='hist', bins=4, alpha=0.5, normed=1)\n",
    "plt.subplot(1,3,2)\n",
    "df['CAPACIDADE_(L)'].plot(kind='hist', bins=4, alpha=0.5, normed=1)\n",
    "plt.subplot(1,3,3)\n",
    "df['LARGURA'].plot(kind='hist', bins=4, alpha=0.5, normed=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From those simple visualizations we can see that the data is Highly unbalanced. This affects the hability of the Network to generalize. Since there are a lot o missing exemple for some categories. Also there are alot o NAN information which affect the netowrk generalization capability. However we can try to see if there is any direct relationship between categories/bins and the predicted output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dlnd-tf-lab]",
   "language": "python",
   "name": "conda-env-dlnd-tf-lab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
